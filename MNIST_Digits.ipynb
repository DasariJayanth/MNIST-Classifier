{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tOoyQ70H00_s"
   },
   "source": [
    "## MNIST Classifier for Digits\n",
    "MNIST is a dataset which has items of handwriting -- the digits 0 through 9.\n",
    "\n",
    "In this notebook we are training an MNIST classifier using two neural networks.\n",
    "1. Shallow Neural Network(Normal NN).\n",
    "2. Convolutional Neural Network(CNN).\n",
    "\n",
    "MNIST dataset is included in tensorflow keras datasets, we are directly using that dataset here.\n",
    "\n",
    "\n",
    "In normal NN, we are training a model that trains to 99% accuracy or above, and does it without a fixed number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from os import path, getcwd, chdir\n",
    "\n",
    "path = r\"C:\\Users\\ASUS\\Downloads\\MNIST\\mnist.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\ASUS\\\\Downloads\\\\MNIST\\\\mnist.npz'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x16494bec5b0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data(path=path)\n",
    "X = training_images\n",
    "X=X.reshape(-1,28,28,1)\n",
    "plt.imshow(X[50,:,:,0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Shallow Neural Network(NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9rvXQGAA0ssC"
   },
   "outputs": [],
   "source": [
    "def train_mnist():\n",
    "    \n",
    "    class myCallback(tf.keras.callbacks.Callback):\n",
    "        def on_epoch_end(self, epoch, logs={}):\n",
    "            if(logs.get('accuracy') > 0.99):\n",
    "                print(\"\\nReached 99% accuracy so cancelling training!\")\n",
    "                self.model.stop_training = True\n",
    "    callbacks = myCallback()            \n",
    "    \n",
    "\n",
    "    mnist = tf.keras.datasets.mnist\n",
    "\n",
    "    (x_train, y_train),(x_test, y_test) = mnist.load_data(path=path)\n",
    "    \n",
    "    x_train = x_train/255\n",
    "    x_test  = x_test/255\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(512,activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(10,activation=tf.nn.softmax)\n",
    "        \n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # model fitting,training\n",
    "    history = model.fit(x_train, y_train, epochs=10, callbacks=[callbacks])\n",
    "    \n",
    "    # Evaluate on the test set\n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "    print(test_acc)\n",
    "    \n",
    "    return history.epoch, history.history['accuracy'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9rvXQGAA0ssC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2003 - accuracy: 0.9406\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0807 - accuracy: 0.9749\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0524 - accuracy: 0.9836\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0370 - accuracy: 0.9879\n",
      "Epoch 5/10\n",
      "1870/1875 [============================>.] - ETA: 0s - loss: 0.0279 - accuracy: 0.9909\n",
      "Reached 99% accuracy so cancelling training!\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0278 - accuracy: 0.9909\n",
      "313/313 [==============================] - 1s 1ms/step - loss: 0.0841 - accuracy: 0.9765\n",
      "0.9764999747276306\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0, 1, 2, 3, 4], 0.9908666610717773)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Convolutional Neural Network(CNN)\n",
    "\n",
    "We can improve the MNIST accuracy using CNN easily rather than using DNN.\n",
    "\n",
    "In CNN, we are training a model that trains to 99.8% accuracy or above with simple CNN architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mnist_conv():\n",
    "\n",
    "    class myCallback(tf.keras.callbacks.Callback):\n",
    "        def on_epoch_end(self, epoch, logs={}):\n",
    "            if(logs.get('accuracy')>0.998):\n",
    "                print(\"\\nReached 99.8% accuracy so cancelling training!\")\n",
    "                self.model.stop_training = True\n",
    "                \n",
    "    # load the dataset\n",
    "    \n",
    "    mnist = tf.keras.datasets.mnist\n",
    "    (training_images, training_labels), (test_images, test_labels) = mnist.load_data(path=path)\n",
    "    \n",
    "    # Normalizing\n",
    "    \n",
    "    # If u want to train over subset of the total training data\n",
    "    # training_images = training_images[:3000]\n",
    "    # training_labels = training_labels[:3000]\n",
    "    training_images=training_images.reshape(-1, 28, 28, 1)\n",
    "    training_images=training_images / 255.0\n",
    "    \n",
    "    test_images = test_images.reshape(10000, 28, 28, 1)\n",
    "    test_images = test_images / 255.0\n",
    "    \n",
    "    callbacks = myCallback()\n",
    "    \n",
    "    \n",
    "    # defining the conv model\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        tf.keras.layers.Conv2D(128, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # model fitting, training the model\n",
    "    history = model.fit(training_images, training_labels, epochs=20, callbacks=[callbacks])\n",
    "    \n",
    "    # Evaluate on the test set\n",
    "    test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "    print(test_acc)\n",
    "\n",
    "    return history.epoch, history.history['accuracy'][-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 58s 31ms/step - loss: 0.1128 - accuracy: 0.9653\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 57s 30ms/step - loss: 0.0390 - accuracy: 0.9880\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 57s 30ms/step - loss: 0.0268 - accuracy: 0.9916\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 53s 28ms/step - loss: 0.0189 - accuracy: 0.9938\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 52s 27ms/step - loss: 0.0127 - accuracy: 0.9957\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 55s 30ms/step - loss: 0.0108 - accuracy: 0.9965\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 51s 27ms/step - loss: 0.0091 - accuracy: 0.9968\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 50s 27ms/step - loss: 0.0077 - accuracy: 0.9974\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 51s 27ms/step - loss: 0.0065 - accuracy: 0.9979\n",
      "Epoch 10/20\n",
      "1874/1875 [============================>.] - ETA: 0s - loss: 0.0056 - accuracy: 0.9983\n",
      "Reached 99.8% accuracy so cancelling training!\n",
      "1875/1875 [==============================] - 50s 27ms/step - loss: 0.0055 - accuracy: 0.9983\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0332 - accuracy: 0.9919\n",
      "0.9919000267982483\n"
     ]
    }
   ],
   "source": [
    "_, _ = train_mnist_conv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe the outputs and the differences in two models training and test accuracy in outputs sections of the models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "introduction-tensorflow",
   "graded_item_id": "d6dew",
   "launcher_item_id": "FExZ4"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
